{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral Cloning Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "*    Use the simulator to collect data of good driving behavior\n",
    "*    Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "*    Train and validate the model with a training and validation set\n",
    "*    Test that the model successfully drives around track one without leaving the road\n",
    "*    Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files Submitted & Code Quality\n",
    "#### 1. Submission includes all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "#### My project includes the following files:\n",
    "\n",
    "* `3_Asigment.ipynb` containing the script to create and train the model\n",
    "* `drive.py` for driving the car in autonomous mode\n",
    "* `model_2_.h5` containing a trained convolution neural network \n",
    "* `writeup_report.md` summarizing the results\n",
    "* `video.mp4` a sample video of the given track with autonomous drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Submission includes functional code\n",
    "\n",
    "Using the Udacity provided simulator and my drive.py file, the car can be driven autonomously around the track by executing\n",
    "\n",
    "* `python drive.py model_2_.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model parameter tuning\n",
    "\n",
    "For the parameter tunning the model uses the AdamOptimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Appropriate training data\n",
    "\n",
    "To create the training data I used the training data given by Udacity. I also tried to drive the track one with good behavior one time forward and once backward. The same procedure was done on the track 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Solution Design Approach\n",
    "\n",
    "The overall strategy for deriving a model architecture was to ...\n",
    "\n",
    "My strategy was to use my own data set. At first I collect my data set with the help of the udacity simulator. I ran each track twice in one way and twice in opposite way. The usage of flip technik was not realy helpfull for me.\n",
    "\n",
    "I use a convolution neural network model similar from the [Nvidia Paper](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf).\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I also crop my image to reduce amount of data feeding into RAM.\n",
    "\n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one. There was one spot where the vehicle fell off the track at the second track I think I should play around with corresction factors. Another way can be so use udacity data set and just add my trimed data set in to it.\n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the first track without leaving the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Nvidia Model Architecture\n",
    "\n",
    "Here is a visualization of the architecture which based on this paper [Nvidia Paper](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf).\n",
    "I crop my images by 50 upper side and 20 from down side of each image. I also use batch normalization between the layers to keep the mean activation near zero. To avoid overfitting I use drop outs flatted fully connected layers. The model used an adam optimizer, so the learning rate was not tuned manually. I used “exponential linear unit” (ELU) which speeds up learning indeep neural networks and leads to higher classification accuracies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "|Layer (type)                 | Output Shape             | Param #  |\n",
    "|-----------------------------|--------------------------|----------|\n",
    "|cropping2d_1 (Cropping2D)    |(None, 90, 320, 3)        |0         |        \n",
    "|lambda_1 (Lambda)            |(None, 90, 320, 3)        |0         |\n",
    "|batch_normalization_1 (Batch |(None, 90, 320, 3)        |12        |\n",
    "|conv2d_1 (Conv2D)            |(None, 43, 158, 24)       |1824      |\n",
    "|conv2d_2 (Conv2D)            |(None, 20, 77, 36)        |21636     |\n",
    "|conv2d_3 (Conv2D)            |(None, 8, 37, 48)         |43248     |\n",
    "|batch_normalization_2 (Batch |(None, 8, 37, 48)         |192       |\n",
    "|conv2d_4 (Conv2D)            |(None, 6, 35, 64)         |27712     |\n",
    "|conv2d_5 (Conv2D)            |(None, 4, 33, 64)         |36928     |\n",
    "|dropout_1 (Dropout)          |(None, 4, 33, 64)         |0         |\n",
    "|flatten_1 (Flatten)          |(None, 8448)              |0         |\n",
    "|dense_1 (Dense)              |(None, 100)               |844900    |\n",
    "|batch_normalization_3 (Batch |(None, 100)               |400       |\n",
    "|dropout_2 (Dropout)          |(None, 100)               |0         |\n",
    "|dense_2 (Dense)              |(None, 50)                |5050      |\n",
    "|batch_normalization_4 (Batch |(None, 50)                |200       |\n",
    "|dropout_3 (Dropout)          |(None, 50)                |0         |\n",
    "|dense_3 (Dense)              |(None, 10)                |510       |\n",
    "|batch_normalization_5 (Batch |(None, 10)                |40        |\n",
    "|dense_4 (Dense)              |(None, 1)                 |11        |\n",
    "\n",
    "Total params: 982,663\n",
    "Trainable params: 982,241\n",
    "Non-trainable params: 422\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model parameter tuning\n",
    "\n",
    "*    The model used an adam optimizer, so the learning rate was not tuned manually.\n",
    "*    I kept the batch size 32\n",
    "*    correction factor= 0.2 for adjust left and right camera images\n",
    "     and ran the model for 12 epochs to make model.py but here just 5 epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Appropriate training data\n",
    "I collect my data with Udacity Simulator. I drove each track twice in one way and twice in opposite way. The usage of flip technik was not realy helpfull for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Appropriate training data\n",
    "I collect my data with Udacity Simulator. I drove each track twice in one way and twice in opposite way. The usage of flip technik was not realy helpfull for me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "To my understanding the way that data set is prepaired play a big role how it will work on autonomous mode. The amount of data set also play a role. As I had no cuda graphic card and the training is very time costly, I could not play more with all ideas which to make my model work better on the second track. By the way it acts quite good up to last slope! :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Cropping2D\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path\n",
    "def load_files(base_path, csv_name = \"driving_log.csv\", correction = 0.2, image_samples=[]):\n",
    "\n",
    "# set the paths of CSV file and where the Images files are    \n",
    "    csv_path= str(base_path) + str(csv_name)\n",
    "    image_Path = str(base_path) + \"IMG/\"\n",
    "    drop_prob = 0.8\n",
    "# open and read each line of CSV file in order to find the specific values for:\n",
    "# center line[0], left line[1] and right camera line[2]   \n",
    "    with open(csv_path) as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        for line in reader:\n",
    "# read out where steering data is stored line[3]            \n",
    "            steering_angle = float(line[3])\n",
    "            for i in range(3):\n",
    "# put each path in file name and image file path             \n",
    "                image_file_name = get_file_field(line[i])\n",
    "                image_file_path = str(image_Path) + str(image_file_name)\n",
    "                \n",
    "# randomly droping steering zero with probability of 0.8 which means only 20 % of the time \n",
    "# images of car riding strait a head streeing zero is put in to data set\n",
    "                if steering_angle == 0 and np.random.rand() < drop_prob:\n",
    "                    continue \n",
    "# Initialinf the data with file path            \n",
    "                data = [image_file_path]\n",
    "# appending steering data with the correcction fo each side cameras to the data                \n",
    "                if i == 0:\n",
    "                    data.append(steering_angle) # center camera\n",
    "                if i == 1:\n",
    "                    data.append(steering_angle + correction) # left camera\n",
    "                if i == 2:\n",
    "                    data.append(steering_angle - correction) # right camera\n",
    "                    \n",
    "                image_samples.append(data)   \n",
    "    return image_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the path and use the name only part\n",
    "def get_file_field(place_holder=\"\"):\n",
    "    \n",
    "    return place_holder.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using generator help out with memory shortage at raining later on\n",
    "# here we manage x_train and y_train data for the training\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "# where the Images are actually are                \n",
    "                name = '/home/kayvan/Documents/Udacity/3_Asignment/Training_Files/IMG/'+batch_sample[0].split('/')[-1]\n",
    "# reading each image convert them for X input data and Y (labels)                  \n",
    "                center_image = cv2.imread(name)\n",
    "                center_image = cv2.cvtColor(center_image,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "                center_angle = float(batch_sample[1])\n",
    "                \n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)                \n",
    "# I used them once but the results was not so good but I kep them here to know later \n",
    "# how can I use some modification to increase data base on small recording dataset\n",
    "\n",
    "                #image_flipped = np.fliplr(center_image)\n",
    "                #center_angle_flipped = - center_angle\n",
    "                #images.append(image_flipped)\n",
    "                #angles.append(center_angle_flipped)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where all my samples are\n",
    "samples = load_files('/home/kayvan/Documents/Udacity/3_Asignment/Training_Files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 11782\n",
      "Validation Samples:  2946\n"
     ]
    }
   ],
   "source": [
    "# split the data to into train_samples, validation_samples\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print('Training Samples:', len(train_samples))\n",
    "print('Validation Samples: ', len(validation_samples))\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples)\n",
    "validation_generator = generator(validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model NVIDIA\n",
    "\n",
    "def Nvidia_model(drop_rate=0.5, input_shape=(160, 320, 3)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 127.5) - 1.))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(Conv2D(24, (5, 5), activation='elu', strides=(2, 2)))\n",
    "    model.add(Conv2D(36, (5, 5), activation='elu', strides=(2, 2)))\n",
    "    model.add(Conv2D(48, (5, 5), activation='elu', strides=(2, 2)))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu', strides=(1, 1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='elu', strides=(1, 1)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_rate))\n",
    "    model.add(Dense(50, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_rate))    \n",
    "    model.add(Dense(10, activation='elu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 90, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 320, 3)        12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 43, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 37, 48)         192       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8448)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               844900    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 982,663\n",
      "Trainable params: 982,241\n",
      "Non-trainable params: 422\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add the model data and fitting\n",
    "model = Nvidia_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "368/368 [==============================] - 377s 1s/step - loss: 0.3109 - val_loss: 0.1104\n",
      "Epoch 2/5\n",
      "368/368 [==============================] - 340s 925ms/step - loss: 0.1374 - val_loss: 0.0990\n",
      "Epoch 3/5\n",
      "368/368 [==============================] - 347s 944ms/step - loss: 0.1168 - val_loss: 0.0948\n",
      "Epoch 4/5\n",
      "368/368 [==============================] - 355s 965ms/step - loss: 0.1085 - val_loss: 0.0843\n",
      "Epoch 5/5\n",
      "368/368 [==============================] - 365s 993ms/step - loss: 0.1031 - val_loss: 0.0845\n"
     ]
    }
   ],
   "source": [
    "# Training \n",
    "# for the training I run with 15 epochs but here I'll go just 5 epochs to generate the plot later on\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "history_object = model.fit_generator(train_generator, \n",
    "            steps_per_epoch=int(len(train_samples)/batch_size), \n",
    "            validation_data=validation_generator, \n",
    "            validation_steps=int(len(validation_samples)/batch_size), \n",
    "            epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_2_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
